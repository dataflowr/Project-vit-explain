{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for performance evaluation of techniques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have four methods:**\n",
    "\n",
    "- Raw Attention (seems to be only mean of weights from input embeddings on first layer).\n",
    "- Attention flow (best in final layer).\n",
    "- Attention Rollout (best in final layer).\n",
    "- Gradient Attention Rollout (best in final layer (most likely)).\n",
    "\n",
    "**We have two possible methods for metric evaluation:**\n",
    "\n",
    "- Blank-out -> generate black spots and look at drop in accuracy.\n",
    "- Gradient input -> **(?)**.\n",
    "\n",
    "**Pipeline for evaluating models:**\n",
    "\n",
    "- Select $N$ images for study.\n",
    "- For each image (also can be done in multiple layers, but time constraint): \n",
    "    - Compute its raw attention, attention flow, rollout, and gradient rollout.\n",
    "    - Compute the blank-out and gradient input.\n",
    "    - Each will yield a vector of size $n_{embedding}$.\n",
    "    - Compute Spearman rank correlation between them and store it\n",
    "\n",
    "We should end up with a table of size $n_{images} \\times n_{methods}$. It suffices to compute mean and standard deviation for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import sys\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vit_rollout import VITAttentionRollout\n",
    "from vit_grad_rollout import VITAttentionGradRollout\n",
    "from vit_flow import VITAttentionFlow\n",
    "\n",
    "import copy\n",
    "import requests\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('facebookresearch/deit:main', \n",
    "        'deit_tiny_patch16_224', pretrained=True)\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, transform):\n",
    "    img = Image.open(image_path)\n",
    "    input_tensor = transform(img).unsqueeze(0)\n",
    "    return input_tensor.to(DEVICE)\n",
    "\n",
    "def get_prediction(scores):\n",
    "    '''Gets the index of max prob and the prob\n",
    "    '''\n",
    "    h_x = F.softmax(scores, dim=1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    # output the prediction\n",
    "    return idx[0].item(), probs[0].item()\n",
    "\n",
    "# idx, prob = get_prediction(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Attention Rollout masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_attention_rollout = 'attention_rollout.txt'\n",
    "file_attention_grad_rollout = 'attention_grad_rollout.txt'\n",
    "file_attention_flow = 'attention_flow.txt'\n",
    "\n",
    "with open(file_attention_rollout, 'w') as f:\n",
    "    pass  # Opening in 'w' mode clears the file\n",
    "\n",
    "with open(file_attention_grad_rollout, 'w') as f:\n",
    "    pass  # Opening in 'w' mode clears the file\n",
    "\n",
    "with open(file_attention_flow, 'w') as f:\n",
    "    pass  # Opening in 'w' mode clears the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = 'images/ILSVRC2012_val_00000'\n",
    "path_suffix = '.JPEG'\n",
    "discard_ratio = 0.9\n",
    "image_size = 224\n",
    "\n",
    "def convert_number(number):\n",
    "    if number < 10:\n",
    "        return '00'+str(number)\n",
    "    if number < 100:\n",
    "        return '0'+str(number)\n",
    "    else:\n",
    "        return str(number)\n",
    "\n",
    "# img = Image.open(path_prefix + image_number_converted + path_suffix)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "c:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [06:00<00:00,  1.83s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [06:02<00:00,  1.84s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [06:02<00:00,  1.84s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [06:00<00:00,  1.83s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [06:00<00:00,  1.83s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [06:02<00:00,  1.84s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:59<00:00,  1.83s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [06:03<00:00,  1.84s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [06:01<00:00,  1.83s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [06:08<00:00,  1.87s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [11:10<00:00,  3.40s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [2:13:50<00:00, 40.76s/it]     \n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:59<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [06:01<00:00,  1.83s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:59<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:59<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:57<00:00,  1.81s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:58<00:00,  1.82s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:57<00:00,  1.81s/it]\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "Using cache found in C:\\Users\\mouha/.cache\\torch\\hub\\facebookresearch_deit_main\n",
      "100%|██████████| 197/197 [05:57<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image being treated: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m image_number_converted \u001b[38;5;241m=\u001b[39m convert_number(image_number)\n\u001b[0;32m      5\u001b[0m image_path \u001b[38;5;241m=\u001b[39m path_prefix \u001b[38;5;241m+\u001b[39m image_number_converted \u001b[38;5;241m+\u001b[39m path_suffix\n\u001b[1;32m----> 6\u001b[0m input_tensor  \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Getting idx\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebookresearch/deit:main\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeit_tiny_patch16_224\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image_path, transform)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, transform):\n\u001b[0;32m      2\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\n\u001b[1;32m----> 3\u001b[0m     input_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m input_tensor\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mouha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:928\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    927\u001b[0m     std \u001b[38;5;241m=\u001b[39m std\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 928\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv_(std)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]"
     ]
    }
   ],
   "source": [
    "for image_number in range(1,61):\n",
    "    print(f\"Current image being treated: {image_number}\")\n",
    "\n",
    "    image_number_converted = convert_number(image_number)\n",
    "    image_path = path_prefix + image_number_converted + path_suffix\n",
    "    input_tensor  = preprocess_image(image_path, transform)\n",
    "\n",
    "    # Getting idx\n",
    "    model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    scores = model(input_tensor)\n",
    "    category_index, _ = get_prediction(scores)\n",
    "\n",
    "    # Attention Rollout\n",
    "    model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)\n",
    "    model.eval()\n",
    "    attention_rollout = VITAttentionRollout(model, discard_ratio=discard_ratio)\n",
    "    mask_attention_rollout = attention_rollout.get_attention_mask(input_tensor).numpy()\n",
    "    mask_attention_rollout = mask_attention_rollout / np.max(mask_attention_rollout)\n",
    "    \n",
    "    with open(file_attention_rollout, 'a') as f:\n",
    "        np.savetxt(f, [mask_attention_rollout], fmt='%.3f', delimiter=',')  # Saving as float\n",
    "\n",
    "    # Gradient Attention Rollout\n",
    "    model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)\n",
    "    model.eval()\n",
    "    attention_grad_rollout = VITAttentionGradRollout(model, discard_ratio=discard_ratio)\n",
    "    mask_attention_grad_rollout = attention_grad_rollout.get_attention_mask(input_tensor, category_index=category_index).numpy()\n",
    "    mask_attention_grad_rollout = mask_attention_grad_rollout / np.max(mask_attention_grad_rollout)\n",
    "    \n",
    "    with open(file_attention_grad_rollout, 'a') as f:\n",
    "        np.savetxt(f, [mask_attention_grad_rollout], fmt='%.3f', delimiter=',')  # Adjust format as needed\n",
    "\n",
    "    # Attention Flow\n",
    "    model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)\n",
    "    model.eval()\n",
    "    attention_flow = VITAttentionFlow(model, discard_ratio=discard_ratio)\n",
    "    mask_attention_flow = attention_flow.get_attention_mask(input_tensor).numpy()\n",
    "    mask_attention_flow = mask_attention_flow / np.max(mask_attention_flow)\n",
    "    \n",
    "    with open(file_attention_flow, 'a') as f:\n",
    "        np.savetxt(f, [mask_attention_flow], fmt='%.3f', delimiter=',')  # Adjust format as needed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# LABELS_URL = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n",
    "# classes = {int(key): value for (key, value) in requests.get(LABELS_URL).json().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor  = preprocess_image(\"examples/input.png\", transform)\n",
    "# scores = model(input_tensor)\n",
    "\n",
    "# def print_preds(scores):\n",
    "#     # print the predictions with their 'probabilities' from the scores\n",
    "#     h_x = F.softmax(scores, dim=1).data.squeeze()\n",
    "#     probs, idx = h_x.sort(0, True)\n",
    "#     probs = probs.numpy()\n",
    "#     idx = idx.numpy()\n",
    "#     # output the prediction\n",
    "#     for i in range(0, 5):\n",
    "#         print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))\n",
    "#     return idx\n",
    "\n",
    "# def get_prediction(scores):\n",
    "#     '''Gets the index of max prob and the prob\n",
    "#     '''\n",
    "#     h_x = F.softmax(scores, dim=1).data.squeeze()\n",
    "#     probs, idx = h_x.sort(0, True)\n",
    "#     # output the prediction\n",
    "#     return idx[0].item(), probs[0].item()\n",
    "\n",
    "# idx, prob = get_prediction(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
